{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1n-wv-zQ5OSHDwUt7YEu7fxAtY0Gu4rDE",
      "authorship_tag": "ABX9TyMYkt6PDmGopQrAGjL41MH/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tatianakami/spark-sentiment-analysis/blob/main/Sentiment_Analysis_Pipeline_ipyn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instala√ß√£o do PySpark**"
      ],
      "metadata": {
        "id": "TP6nIg9nHoAT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nILW6h9WAnCj"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iniciando uma sess√£o**"
      ],
      "metadata": {
        "id": "-Z1eswDYHvSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"analise_nlp\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "p8XAGh4BBC-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"analise_nlp\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "Lvy7LGNaHkb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leitura dos **dados**"
      ],
      "metadata": {
        "id": "YcGXI1_7JE9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"analise_nlp\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Definindo o caminho direto para o arquivo dentro da pasta que encontramos\n",
        "caminho_imdb = \"/content/drive/MyDrive/ModuloSpark2_processamento_de_linguagem_natural/imdb-reviews-pt-br.csv\"\n",
        "\n",
        "# Lendo os dados com as configura√ß√µes para texto (NLP)\n",
        "dados = spark.read.csv(caminho_imdb,\n",
        "                       escape=\"\\\\\",\n",
        "                       header=True,\n",
        "                       inferSchema=True)\n",
        "\n",
        "# Mostrando o resultado para confirmar\n",
        "print(f\"Sucesso! O dataset tem {dados.count()} avalia√ß√µes.\")\n",
        "dados.show(5, truncate=50) # truncate=50 ajuda a ler o texto sem cortar muito"
      ],
      "metadata": {
        "id": "PYthGyTBOUnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explorando os dados(estrutura, tamanho dos dados)**"
      ],
      "metadata": {
        "id": "8_0ucgdRVCZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Numero de linhas:{dados.count()}', f'numero de colunas:{len(dados.columns)}')"
      ],
      "metadata": {
        "id": "SoMDMqCdVMuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Campos e Tipos**"
      ],
      "metadata": {
        "id": "CMyKQSLQWHDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados.printSchema()"
      ],
      "metadata": {
        "id": "3--gb1owWQK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tamanho dos dados**"
      ],
      "metadata": {
        "id": "WIIUKr-Gf7kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'N¬∫ linhas:{dados.count()}',f'\\nN¬∫ colunas:{len(dados.columns)}')"
      ],
      "metadata": {
        "id": "aAohDttggBs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteudo\n",
        "# dados.head() n√£o traz a estrutura desejada\n",
        "\n",
        "dados.limit(99).show()"
      ],
      "metadata": {
        "id": "7_7t7uNwgadn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apresentando alguns coment√°rios ditos como negativo ou positivo.\n",
        "\n",
        "print(\"Negativo\")\n",
        "dados.filter(dados.id == 190).select('text_pt').show(truncate=False)\n",
        "\n",
        "print(\"Positivo\")\n",
        "dados.filter(dados.id == 12427).select('text_pt').show(truncate=False)"
      ],
      "metadata": {
        "id": "Km1t0kVTgg6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo o arquivo com \"paredes refor√ßadas\" (par√¢metros extras)\n",
        "dados = spark.read.csv(caminho_imdb,\n",
        "                       header=True,\n",
        "                       inferSchema=True,\n",
        "                       quote=\"\\\"\",       # Diz que o texto est√° protegido por aspas\n",
        "                       escape=\"\\\"\",      # Diz para n√£o se assustar com aspas duplas \"\"\n",
        "                       multiLine=True)   # Avisa que um coment√°rio pode pular de linha\n",
        "\n",
        "# AGORA TESTE O NEGATIVO NOVAMENTE:\n",
        "print(\"Negativo (ID 190) - Agora deve estar em Portugu√™s:\")\n",
        "dados.filter(dados.id == 190).select('text_pt').show(truncate=False)"
      ],
      "metadata": {
        "id": "PopiMr87g86E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contabilizando os tipos de coment√°rios\n",
        "dados.groupBy('sentiment').count().show()"
      ],
      "metadata": {
        "id": "joJBaFf4hFUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Propor√ß√£o dos coment√°rios\n",
        "# conseguimos perceber que nossos dados s√£o balanceados.\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "conta_classe=dados.groupBy('sentiment').count()\n",
        "conta_classe.withColumn(\"(%)\", f.round(f.col('count')/f.sum('count').over(Window.partitionBy())*100, 2)).show()"
      ],
      "metadata": {
        "id": "zU9WDKf-hH5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "b5NclmJ1lVfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados.limit(10).show()"
      ],
      "metadata": {
        "id": "tntExazila8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordCloud**"
      ],
      "metadata": {
        "id": "MAcc-aH5lnw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amostra = dados.select('text_pt').sample(fraction = 0.1, seed = 101)"
      ],
      "metadata": {
        "id": "VFsHqVWhltp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Transformar em uma lista que o Python entenda (Aten√ß√£o aos colchetes!)\n",
        "tudo = [texto['text_pt'] for texto in amostra.collect()]"
      ],
      "metadata": {
        "id": "RPaGYbZymBWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Criar a Nuvem de Palavras\n",
        "\n",
        "wordcloud = WordCloud(background_color='white',\n",
        "                      width=1000,\n",
        "                      height=600,\n",
        "                      collocations=False,\n",
        "                      prefer_horizontal=1.0).generate(str(tudo))"
      ],
      "metadata": {
        "id": "8ARv6GkKmHrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Mostrar na tela\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\") # Esconde os n√∫meros dos eixos para ficar limpo\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tVxnD7JrmMF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limpeza:caracteres especiais**"
      ],
      "metadata": {
        "id": "bzMLRobtReJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "id": "-jgQyAERRkny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amostra = spark.createDataFrame([\n",
        "                (\"Oi, JP! Blz?\",),\n",
        "                (\"$$$\\\\ |~ Parab√©ns ~| \\\\$$$\",),\n",
        "                (\"(#amovc #paz&amor ^.^)\",),\n",
        "                (\"\\\"bora *_* \\\"\",),\n",
        "                (\"=>->'...``` vc foi selecionad@ ¬¥¬¥¬¥...'<=<-\",),\n",
        "                (\"{comprar: arroz; feij√£o e pepino} //\",),\n",
        "                (\"!\\\"#$&'()*+,-./:;<=>?@[\\]^_`{|}~\",),\n",
        "                (\"ana@gmail.com\",)\n",
        "        ], [\"textos\"])"
      ],
      "metadata": {
        "id": "YdZwN46pRyeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f"
      ],
      "metadata": {
        "id": "xv82xhsqZLrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amostra = amostra.withColumn(\"texto_regex\", f.regexp_replace(\"textos\", \"\\$\", \"\"))"
      ],
      "metadata": {
        "id": "rRvadoa4ZP7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amostra = amostra.withColumn(\"texto_regex\", f.regexp_replace(\"textos\", \"[\\$#,\\\"!%&'()*+-./;:<=>?@^_`¬¥{|}~\\\\\\\\]\", \"\"))\n",
        "amostra.show(truncate = False)"
      ],
      "metadata": {
        "id": "tM222o9KZT7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amostra = amostra.withColumn(\"texto_limpo\", f.trim(amostra.texto_regex))\n",
        "amostra.show(truncate = False)"
      ],
      "metadata": {
        "id": "Xycd97nGZWn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = dados.withColumn(\"texto_regex\", f.regexp_replace(\"text_en\", \"[\\$#,\\\"!%&'()*+-./;;<=>?@^_`¬¥{|}~\\\\\\\\]\", \"\"))\n",
        "\n",
        "dados.limit(2).show(truncate = False)"
      ],
      "metadata": {
        "id": "Zpfn_BXRZnAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = dados.withColumn(\"texto_limpo\", f.trim(dados.texto_regex))"
      ],
      "metadata": {
        "id": "C_oA1HPuZrIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados.limit(2).show(truncate=False, vertical=True)"
      ],
      "metadata": {
        "id": "P8rJvmMzZ9nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma lista de palavras que \"entregam\" que o texto √© ingl√™s\n",
        "stopwords_ingles = [\" the \", \" and \", \" is \", \" of \", \" to \", \" with \"]\n",
        "\n",
        "# Filtrando para manter APENAS o que N√ÉO tem essas palavras\n",
        "dados_portugues = dados\n",
        "for palavra in stopwords_ingles:\n",
        "    # O sinal ~ significa \"N√ÉO\"\n",
        "    dados_portugues = dados_portugues.filter(~f.col(\"text_pt\").contains(palavra))\n",
        "\n",
        "print(f\"Agora voc√™ tem {dados_portugues.count()} linhas apenas em portugu√™s!\")"
      ],
      "metadata": {
        "id": "L6Qr7QehaeZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando o antes e o depois\n",
        "print(f\"Total de linhas antes: {dados.count()}\")\n",
        "print(f\"Total de linhas s√≥ em Portugu√™s: {dados_portugues.count()}\")\n",
        "\n",
        "# Ver o resultado\n",
        "dados_portugues.select(\"text_pt\").show(5, truncate=100)"
      ],
      "metadata": {
        "id": "tvwMPQ3ba2ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O Fatiador de Palavras (Tokeniza√ß√£o)**"
      ],
      "metadata": {
        "id": "Nil2ZvoibKw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "from pyspark.sql.types import IntegerType\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "# 1. Preparando a m√°quina de fatiar.\n",
        "# Ela pega o 'texto_limpo' e joga o resultado na coluna 'tokens'.\n",
        "tokenizer = Tokenizer(inputCol=\"texto_limpo\", outputCol=\"tokens\")\n",
        "\n",
        "# 2. Passo os meus dados pela m√°quina.\n",
        "# O legal √© que o Tokenizer j√° deixa tudo MIN√öSCULO sozinho! Menos um trabalho pra mim.\n",
        "tokenizado = tokenizer.transform(dados)\n",
        "\n",
        "# 3. Vou criar uma regrinha r√°pida para contar quantas palavras tem em cada frase.\n",
        "# √â um contador de palavras autom√°tico.\n",
        "countTokens = f.udf(lambda lista: len(lista), IntegerType())\n",
        "\n",
        "# 4. Agora eu mostro o texto, a lista de palavras e o total de palavras (frequ√™ncia).\n",
        "tokenizado.select(\"texto_limpo\", \"tokens\") \\\n",
        "    .withColumn(\"Freq_tokens\", countTokens(f.col(\"tokens\"))).show()"
      ],
      "metadata": {
        "id": "Nf6Eoeazd9BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StopWords**"
      ],
      "metadata": {
        "id": "lBCzUdH27zA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "suHLnAS172JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Baixando a \"lista de lixo\" oficial do portugu√™s (NLTK)\n",
        "nltk.download(\"stopwords\")\n",
        "stop_portugues = stopwords.words(\"portuguese\")\n",
        "\n",
        "# 2. Configurando a m√°quina de limpeza\n",
        "# Ela pega meus 'tokens' e cria a coluna 'texto_final' sem a sujeira.\n",
        "remover = StopWordsRemover(inputCol=\"tokens\",\n",
        "                           outputCol=\"texto_final\",\n",
        "                           stopWords=stop_portugues)\n",
        "\n",
        "# 3. Rodando a limpeza nos meus dados tokenizados\n",
        "feature_data = remover.transform(tokenizado)\n",
        "\n",
        "# 4.  Vamos ver quanto \"peso\" a gente perdeu?\n",
        "print(\"Comparando a dieta dos tokens:\")\n",
        "feature_data.select(\"tokens\", \"texto_final\") \\\n",
        "    .withColumn(\"Antes\", countTokens(f.col(\"tokens\"))) \\\n",
        "    .withColumn(\"Depois\", countTokens(f.col(\"texto_final\"))) \\\n",
        "    .show(5)"
      ],
      "metadata": {
        "id": "77EmH_IC8B4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of words**"
      ],
      "metadata": {
        "id": "cNqMv7OcDhpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer"
      ],
      "metadata": {
        "id": "Aj6U89n3DZ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Preparando a  \"Sacola\".\n",
        "# Ela olha para o 'texto_final' (que j√° t√° limpo) e cria a coluna 'CountVec'.\n",
        "cv = CountVectorizer(inputCol=\"texto_final\", outputCol=\"CountVec\")\n",
        "\n",
        "# 2. O 'fit' √© o Spark aprendendo quais palavras existem no mundo.\n",
        "# Ele cria um dicion√°rio (modelo) com todas as palavras √∫nicas.\n",
        "modelo_sacola = cv.fit(feature_data)\n",
        "\n",
        "# 3. O 'transform' √© onde ele realmente carimba os n√∫meros nos nossos dados.\n",
        "dados_vetorizados = modelo_sacola.transform(feature_data)\n",
        "\n",
        "# 4. as palavras que ele aprendeu?\n",
        "# Isso aqui √© o nosso \"Dicion√°rio do Spark\".\n",
        "print(\"As primeiras palavras do nosso dicion√°rio:\")\n",
        "print(modelo_sacola.vocabulary[:10])\n",
        "\n",
        "# 5. Mostrando o resultado final (Palavras vs N√∫meros)\n",
        "dados_vetorizados.select('texto_final', 'CountVec').limit(5).show(truncate=False)"
      ],
      "metadata": {
        "id": "Mu8jbHIxDd_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hashing TF**"
      ],
      "metadata": {
        "id": "4yVyH-JQFBj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF\n",
        "\n",
        "# 1. Preparando o \"Funil\" de palavras.\n",
        "# Eu digo de onde vem (texto_final) e onde coloco o resultado (hashingTF).\n",
        "htf = HashingTF(inputCol=\"texto_final\", outputCol=\"hashingTF\")\n",
        "\n",
        "# 2. Aqui eu defino o limite.\n",
        "# \"Spark, eu s√≥ quero 50 gavetas para guardar tudo isso, ok?\"\n",
        "htf.setNumFeatures(50)\n",
        "\n",
        "# 3. Rodando a transforma√ß√£o.\n",
        "# Repare que aqui N√ÉO usamos o .fit(), vamos direto para o .transform().\n",
        "# Isso acontece porque o Hashing √© uma conta matem√°tica, ele n√£o precisa \"aprender\" as palavras antes.\n",
        "dados_hashing = htf.transform(feature_data)\n",
        "\n",
        "# 4. Vendo o resultado compacto\n",
        "dados_hashing.select(\"texto_final\", \"hashingTF\").limit(5).show(truncate=False)"
      ],
      "metadata": {
        "id": "ZCMcKEHRFDo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "\n",
        "# 1. Preparando o \"Juiz\" (IDF).\n",
        "# Ele olha para os n√∫meros do HashingTF e decide quem ganha mais peso.\n",
        "# O resultado vai para a coluna 'features' (esse √© o nome padr√£o que a IA gosta).\n",
        "idf = IDF(inputCol=\"hashingTF\", outputCol=\"features\")\n",
        "\n",
        "# 2. O 'fit' aqui √© obrigat√≥rio!\n",
        "# O Spark precisa ler a base toda para saber quais palavras s√£o \"comuns\" e quais s√£o \"raras\".\n",
        "modelo_idf = idf.fit(dados_hashing)\n",
        "\n",
        "# 3. Agora ele carimba os pesos nos nossos dados.\n",
        "dados_finalizados = modelo_idf.transform(dados_hashing)\n",
        "\n",
        "# 4. Vendo o resultado (Agora os n√∫meros n√£o s√£o mais inteiros, s√£o decimais/pesos!)\n",
        "dados_finalizados.select('texto_final', 'features').limit(5).show(truncate=False)"
      ],
      "metadata": {
        "id": "xtvgiIHYGmS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline**"
      ],
      "metadata": {
        "id": "fNYW-r8LJAF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "\n",
        "# 1. PE√áA 1: O fatiador de palavras\n",
        "tokenizer = Tokenizer(inputCol=\"texto_limpo\", outputCol=\"tokens\")\n",
        "\n",
        "# 2. PE√áA 2: O filtro de palavras in√∫teis\n",
        "stopwords = StopWordsRemover(inputCol=\"tokens\", outputCol=\"texto_final\")\n",
        "\n",
        "# 3. PE√áA 3: O contador r√°pido (limitando a 1000 palavras para ser potente)\n",
        "hashingTF = HashingTF(inputCol=\"texto_final\", outputCol=\"HTF\", numFeatures=1000)\n",
        "\n",
        "# 4. PE√áA 4: O juiz que d√° peso ao que importa (TF-IDF)\n",
        "tfidf = IDF(inputCol=\"HTF\", outputCol=\"features\")\n",
        "\n",
        "# üöÄ A ESTEIRA (Pipeline): Coloco as pe√ßas na ordem certa\n",
        "pipeline_da_tati = Pipeline(stages=[tokenizer, stopwords, hashingTF, tfidf])\n",
        "\n",
        "# 5. Ligo a f√°brica!\n",
        "# O .fit() aprende com os dados e o .transform() entrega o resultado pronto.\n",
        "dados_finalizados = pipeline_da_tati.fit(dados).transform(dados)\n",
        "\n",
        "# 6. Conferindo o final da linha de produ√ß√£o\n",
        "dados_finalizados.select(\"sentiment\", \"features\").show(5)"
      ],
      "metadata": {
        "id": "nBwNLsTJJDlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n"
      ],
      "metadata": {
        "id": "Ir8ho1ObfxDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Separando os dados (70% pra estudar, 30% pra testar)\n",
        "# A 'seed' garante que o sorteio seja sempre igual toda vez que eu rodar.\n",
        "treino, teste = dados.randomSplit([0.7, 0.3], seed=101)\n",
        "\n",
        "# 2. O MOMENTO DO ESTUDO (.fit)\n",
        "# Aqui o Pipeline vai rodar tudo: limpar, tokenizar, pesar e a √Årvore vai criar as regras.\n",
        "# O resultado √© o 'modelo_pronto'.\n",
        "modelo_pronto = pipeline.fit(treino)\n",
        "\n",
        "# 3. O MOMENTO DA PROVA (.transform)\n",
        "# Agora eu pe√ßo para o modelo tentar adivinhar o sentimento dos dados de TESTE.\n",
        "previsoes = modelo_pronto.transform(teste)\n",
        "\n",
        "# 4. Vendo o resultado (O que era real vs O que a IA achou)\n",
        "previsoes.select(\"label\", \"prediction\").show(10)"
      ],
      "metadata": {
        "id": "CjaJytshi2_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2.  √Årvore de Decis√£o,\n",
        "# garantindo que ela use o 'label' que j√° est√° l√°:\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label', maxDepth=10)\n",
        "\n",
        "# 3. o pipeline e para o fit:\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[tokenizer, stopwords, hashingTF, tfidf, dt])\n",
        "\n",
        "# 4. Agora sim, treine o modelo:\n",
        "modelo_pronto = pipeline.fit(treino)"
      ],
      "metadata": {
        "id": "hCmBXU1njWB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Teste e m√©tricas**"
      ],
      "metadata": {
        "id": "tHsgIFf0kTOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = modelo_pronto.transform(teste)\n",
        "\n",
        "# 2. Agora o avaliador vai encontrar a vari√°vel!\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "prof_avaliador = MulticlassClassificationEvaluator(labelCol='label',\n",
        "                                                   predictionCol='prediction',\n",
        "                                                   metricName='accuracy')\n",
        "\n",
        "# mesmo nome\n",
        "nota_final = prof_avaliador.evaluate(predictions)\n",
        "\n",
        "print(f\"Acur√°cia: {nota_final:.2f}\")"
      ],
      "metadata": {
        "id": "rYPfNSTtlMlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Crio as frases que eu quero que a IA classifique.\n",
        "# IMPORTANTE: A coluna tem que ter o mesmo nome (texto_limpo) que o Pipeline espera!\n",
        "frases_novas = spark.createDataFrame([\n",
        "        (1, \"This is without doubt the worst movie i have ever seen, I hated the acting of the actor.\"), # Ruim\n",
        "        (0, \"I loved the movie, excellent acting!\"), # Bom\n",
        "    ], [\"id\", \"texto_limpo\"])\n",
        "\n",
        "# 2. Uso o meu modelo treinado para \"adivinhar\"\n",
        "# Ele vai fazer a faxina, tokenizar, pesar e dar o veredito sozinho.\n",
        "resultado_final = modelo_pronto.transform(frases_novas)\n",
        "\n",
        "# 3. Mostro o resultado na tela\n",
        "resultado_final.select(\"texto_limpo\", \"prediction\").show(truncate=False)"
      ],
      "metadata": {
        "id": "OXp4_KrzmMLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  salvar seu modelo e usar depois sem precisar treinar de novo\n",
        "modelo_pronto.save(\"modelo_sentimentos_imdb_v1\")\n",
        "\n",
        "# Calcule o F1-Score (criterio)\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n",
        "f1 = evaluator_f1.evaluate(predictions)\n",
        "print(f\"F1-Score do Modelo: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "rSGsnXPgp7ER"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}